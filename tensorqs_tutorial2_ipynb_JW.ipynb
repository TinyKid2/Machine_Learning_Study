{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gfyw1YsO2L7f"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HK-8-46t2L7h"
   },
   "source": [
    "\n",
    "[파이토치(PyTorch) 기본 익히기](intro.html) ||\n",
    "[빠른 시작](quickstart_tutorial.html) ||\n",
    "**텐서(Tensor)** ||\n",
    "[Dataset과 Dataloader](data_tutorial.html) ||\n",
    "[변형(Transform)](transforms_tutorial.html) ||\n",
    "[신경망 모델 구성하기](buildmodel_tutorial.html) ||\n",
    "[Autograd](autogradqs_tutorial.html) ||\n",
    "[최적화(Optimization)](optimization_tutorial.html) ||\n",
    "[모델 저장하고 불러오기](saveloadrun_tutorial.html)\n",
    "\n",
    "# 텐서(Tensor)\n",
    "\n",
    "텐서(tensor)는 배열(array)이나 행렬(matrix)과 매우 유사한 특수한 자료구조입니다.\n",
    "PyTorch에서는 텐서를 사용하여 모델의 입력(input)과 출력(output), 그리고 모델의 매개변수들을 부호화(encode)합니다.\n",
    "\n",
    "텐서는 GPU나 다른 하드웨어 가속기에서 실행할 수 있다는 점만 제외하면 [NumPy](https://numpy.org) 의 ndarray와 유사합니다.\n",
    "실제로 텐서와 NumPy 배열(array)은 종종 동일한 내부(underly) 메모리를 공유할 수 있어 데이터를 복수할 필요가 없습니다. (`bridge-to-np-label` 참고)\n",
    "텐서는 또한 ([Autograd](autogradqs_tutorial.html)_ 장에서 살펴볼) 자동 미분(automatic differentiation)에 최적화되어 있습니다.\n",
    "ndarray에 익숙하다면 Tensor API를 바로 사용할 수 있을 것입니다. 아니라면, 아래 내용을 함께 보시죠!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zPeagQOG2L7k"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyNGbrse2L7l"
   },
   "source": [
    "## 텐서(tensor) 초기화\n",
    "\n",
    "텐서는 여러가지 방법으로 초기화할 수 있습니다. 다음 예를 살펴보세요:\n",
    "\n",
    "**데이터로부터 직접(directly) 생성하기**\n",
    "\n",
    "데이터로부터 직접 텐서를 생성할 수 있습니다. 데이터의 자료형(data type)은 자동으로 유추합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aMeF0oMj2L7m",
    "outputId": "e8498fda-cf2a-425d-f72a-07be33f49e6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "#  type(data), type(x_data)\n",
    "x_data # 이곳 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9nkSKKu2L7n"
   },
   "source": [
    "**NumPy 배열로부터 생성하기**\n",
    "\n",
    "텐서는 NumPy 배열로 생성할 수 있습니다. (그 반대도 가능합니다 - `bridge-to-np-label` 참고)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYTgQ3-k2L7n",
    "outputId": "226c4bb2-1d02-4f5a-cd2f-3c559d11c29a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor, numpy.ndarray)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "type(np_array), type(x_np), type(x_np.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6RUuhg02L7n"
   },
   "source": [
    "**다른 텐서로부터 생성하기:**\n",
    "\n",
    "명시적으로 재정의(override)하지 않는다면, 인자로 주어진 텐서의 속성(모양(shape), 자료형(datatype))을 유지합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrwmpCzg2L7p",
    "outputId": "50a849c2-7a39-4132-9c96-603d67a4780d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.3491, 0.3389],\n",
      "        [0.4118, 0.4157]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # x_data의 속성을 유지합니다.\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\");\n",
    "\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soQrfH383jFT",
    "outputId": "524911fd-8c32-4e61-cf97-121b05450092"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1.],\n",
       "        [1., 1.]]),\n",
       " array([[1, 1],\n",
       "        [1, 1]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(x_data.shape), np.ones_like(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKYCWMEX2L7q"
   },
   "source": [
    "**무작위(random) 또는 상수(constant) 값을 사용하기:**\n",
    "\n",
    "``shape`` 은 텐서의 차원(dimension)을 나타내는 튜플(tuple)로, 아래 함수들에서는 출력 텐서의 차원을 결정합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2w3wJIsq2L7r",
    "outputId": "ac7bc9b9-eb93-4a35-bd7a-9baadc211cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.7576, 0.2793, 0.4031],\n",
      "        [0.7347, 0.0293, 0.7999]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1); # 이곳 변형, 나중에 시드넘버를 맞춰야 할수도 있으므로\n",
    "\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n",
    "rand_tensor.shape, ones_tensor.shape, zeros_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4IpaOxI2L7r"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsuAPWS42L7r"
   },
   "source": [
    "## 텐서의 속성(Attribute)\n",
    "\n",
    "텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타냅니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5HybBnZ2L7s",
    "outputId": "1ee05aab-7a4d-4bbf-f9db-abfa2aa1cc00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n",
      "tensor([[0.8750, 0.5059, 0.2366, 0.7570],\n",
      "        [0.2346, 0.6471, 0.3556, 0.4452],\n",
      "        [0.0193, 0.2616, 0.7713, 0.3785]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjdb3BCx2L7s"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfITuN7v2L7s"
   },
   "source": [
    "## 텐서 연산(Operation)\n",
    "\n",
    "전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산, 선형 대수,\n",
    "임의 샘플링(random sampling) 등, 100가지 이상의 텐서 연산들을\n",
    "[여기](https://pytorch.org/docs/stable/torch.html)_ 에서 확인할 수 있습니다.\n",
    "\n",
    "각 연산들은 (일반적으로 CPU보다 빠른) GPU에서 실행할 수 있습니다. Colab을 사용한다면,\n",
    "Edit > Notebook Settings 에서 GPU를 할당할 수 있습니다.\n",
    "\n",
    "기본적으로 텐서는 CPU에 생성됩니다. ``.to`` 메소드를 사용하면 (GPU의 가용성(availability)을 확인한 뒤)\n",
    "GPU로 텐서를 명시적으로 이동할 수 있습니다. 장치들 간에 큰 텐서들을 복사하는 것은 시간과 메모리 측면에서 비용이\n",
    "많이든다는 것을 기억하세요!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78ksnpH75bVj",
    "outputId": "b4cb2320-969b-424d-ecb2-b8744699fa4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "9SyeJnVo2L7t"
   },
   "outputs": [],
   "source": [
    "# GPU가 존재하면 텐서를 이동합니다\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b9v5EB65eq5",
    "outputId": "1dd0a4a0-f24a-45d3-c645-ed6c86b00202"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkDnxNQ12L7t"
   },
   "source": [
    "목록에서 몇몇 연산들을 시도해보세요.\n",
    "NumPy API에 익숙하다면 Tensor API를 사용하는 것은 식은 죽 먹기라는 것을 알게 되실 겁니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qY0d23U32L7t"
   },
   "source": [
    "**NumPy식의 표준 인덱싱과 슬라이싱:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hh2qtc762L7t",
    "outputId": "eb6d99a8-50ed-4d1d-bca6-a7b36628290c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First row's size: torch.Size([4])\n",
      "First row's shape: torch.Size([4])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First row's size: {tensor[0].size()}\") # 이곳 수정\n",
    "print(f\"First row's shape: {tensor[0].shape}\") # 이곳 수정\n",
    "\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwEvzMcG2L7t"
   },
   "source": [
    "**텐서 합치기** ``torch.cat`` 을 사용하여 주어진 차원에 따라 일련의 텐서를 연결할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "``torch.cat`` 과 미묘하게 다른 또 다른 텐서 결합 연산인\n",
    "[torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html)_ 도 참고해보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wf4XGXxn2L7u",
    "outputId": "587adad8-98f9-47d4-d848-1e709009b888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofURRshF5MyX",
    "outputId": "62cebd52-87a1-49eb-94e2-fcdf7360eb22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 4])\n",
      "tensor([[[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack([tensor, tensor, tensor]).shape)# 쌓아 올리는 것 # 이곳 수정\n",
    "print(torch.stack([tensor, tensor, tensor]))# 그냥 합치는 것 # 이곳 수정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IusjS_yf5uho",
    "outputId": "4f3b2a6d-ed7b-438b-8f4b-c9f58ef1ff36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 4])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.vstack([tensor, tensor, tensor]).shape) # verticle하게 합치는 것 # 이곳 수정\n",
    "print(torch.vstack([tensor, tensor, tensor]))# 이곳 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6kK4sRcF51jU",
    "outputId": "fa596255-8bd0-4778-c234-5d22eb9c4cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 12])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.hstack([tensor, tensor, tensor]).shape)# horizon 하게 합치는 것 # 이곳 수정\n",
    "print(torch.hstack([tensor, tensor, tensor]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqvkGCCD2L7u"
   },
   "source": [
    "**산술 연산(Arithmetic operations)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0pjqu622L7u",
    "outputId": "a45ccd80-a390-4001-f422-2f6cd3a4a70d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.matmul : \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "torch.mul : \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다. y1, y2, y3은 모두 같은 값을 갖습니다.\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "print(f\"torch.matmul : \\n {torch.matmul(tensor, tensor.T, out=y3)}\") # 이곳 수정\n",
    "\n",
    "\n",
    "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "print(f\"torch.mul : \\n {torch.mul(tensor, tensor, out=z3)}\") # 이곳 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga2m-iWh2L7u"
   },
   "source": [
    "**단일-요소(single-element) 텐서** 텐서의 모든 값을 하나로 집계(aggregate)하여 요소가 하나인 텐서의 경우,\n",
    "``item()`` 을 사용하여 Python 숫자 값으로 변환할 수 있습니다:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QbWN0FHZ2L7u",
    "outputId": "18bc19f5-71e9-417f-ebb4-66543c3e725d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.)\n",
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "print(agg)\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tURzaE1_2L7u"
   },
   "source": [
    "**바꿔치기(in-place) 연산**\n",
    "연산 결과를 피연산자(operand)에 저장하는 연산을 바꿔치기 연산이라고 부르며, ``_`` 접미사를 갖습니다.\n",
    "예를 들어: ``x.copy_(y)`` 나 ``x.t_()`` 는 ``x`` 를 변경합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RboHpBu2L7u",
    "outputId": "2b2a8727-2448-4d8e-b023-63fe3e504a4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRVNxg4j2L7v"
   },
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>바꿔치기 연산은 메모리를 일부 절약하지만, 기록(history)이 즉시 삭제되어 도함수(derivative) 계산에 문제가 발생할 수 있습니다.\n",
    "     따라서, 사용을 권장하지 않습니다.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzrtFMzQ2L7v"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nihFTW4b2L7v"
   },
   "source": [
    "\n",
    "## NumPy 변환(Bridge)\n",
    "CPU 상의 텐서와 NumPy 배열은 <u>메모리 공간을 공유</u>하기 때문에, 하나를 변경하면 다른 하나도 변경됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXT8RoNL2L7v"
   },
   "source": [
    "### 텐서를 NumPy 배열로 변환하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvNH36QB2L7v",
    "outputId": "ceb076ba-dd52-4aec-b938-963186c90a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, numpy.ndarray)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "type(t), type(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ne-Af63j2L7v"
   },
   "source": [
    "텐서의 <u>변경 사항</u>이 NumPy 배열에 반영됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZvXQU692L7v",
    "outputId": "9cc5e254-1319-491b-dd3f-75bb04e68450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([6., 6., 6., 6., 6.])\n",
      "n: [6. 6. 6. 6. 6.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9JA1Ozs2L7v"
   },
   "source": [
    "### NumPy 배열을 텐서로 변환하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1WbZGef2L7w",
    "outputId": "4f0b2021-0a0e-4619-b39b-b782d9e5aed1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "type(n), type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ev7slR2S7AbK",
    "outputId": "cd4ec586-8f64-4a4d-9a8f-95e737536a14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hBVzYvK2L7w"
   },
   "source": [
    "NumPy 배열의 변경 사항이 텐서에 반영됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-nTIzn72L7w",
    "outputId": "2fea995b-b3c8-4768-f8a6-7763e3e41f87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([6., 6., 6., 6., 6.], dtype=torch.float64)\n",
      "n: [6. 6. 6. 6. 6.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqk0tKxH7GOo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
