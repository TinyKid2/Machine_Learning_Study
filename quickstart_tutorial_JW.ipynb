{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GNQ5ABOD8tY9"
   },
   "outputs": [],
   "source": [
    "# Google Colab에서 노트북을 실행하실 때에는\n",
    "# https://tutorials.pytorch.kr/beginner/colab 를 참고하세요.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESmHJbJo8tY-"
   },
   "source": [
    "\n",
    "[파이토치(PyTorch) 기본 익히기](intro.html) ||\n",
    "**빠른 시작** ||\n",
    "[텐서(Tensor)](tensorqs_tutorial.html) ||\n",
    "[Dataset과 Dataloader](data_tutorial.html) ||\n",
    "[변형(Transform)](transforms_tutorial.html) ||\n",
    "[신경망 모델 구성하기](buildmodel_tutorial.html) ||\n",
    "[Autograd](autogradqs_tutorial.html) ||\n",
    "[최적화(Optimization)](optimization_tutorial.html) ||\n",
    "[모델 저장하고 불러오기](saveloadrun_tutorial.html)\n",
    "\n",
    "# 빠른 시작(Quickstart)\n",
    "이번 장에서는 기계 학습의 일반적인 작업들을 위한 API를 통해 실행됩니다. 더 자세히 알아보려면 각 장(section)의 링크를 참고하세요.\n",
    "\n",
    "## 데이터 작업하기\n",
    "파이토치(PyTorch)에는 [데이터 작업을 위한 기본 요소](https://pytorch.org/docs/stable/data.html) 두가지인\n",
    "``torch.utils.data.DataLoader`` 와 ``torch.utils.data.Dataset`` 가 있습니다.\n",
    "``Dataset`` 은 샘플과 정답(label)을 저장하고, ``DataLoader`` 는 ``Dataset`` 을 순회 가능한 객체(iterable)로 감쌉니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "TSXt5vQe8tY_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJI_bPPh8tY_"
   },
   "source": [
    "PyTorch는 [TorchText](https://pytorch.org/text/stable/index.html), [TorchVision](https://pytorch.org/vision/stable/index.html) 및\n",
    "[TorchAudio](https://pytorch.org/audio/stable/index.html) 와 같이 도메인 특화 라이브러리를 데이터셋과 함께 제공하고 있습니다.\n",
    "이 튜토리얼에서는 TorchVision 데이터셋을 사용하도록 하겠습니다.\n",
    "\n",
    "``torchvision.datasets`` 모듈은 CIFAR, COCO 등과 같은 다양한 실제 비전(vision) 데이터에 대한\n",
    "``Dataset``\\ ([전체 목록은 여기](https://pytorch.org/vision/stable/datasets.html))\\ 을 포함하고 있습니다.\n",
    "이 튜토리얼에서는 FasionMNIST 데이터셋을 사용합니다.\n",
    "모든 TorchVision ``Dataset`` 은 샘플과 정답을 각각 변경하기 위한 ``transform`` 과 ``target_transform`` 의 두 인자를 포함합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cNZ_LQM8tZA",
    "outputId": "1575e293-6f99-486e-c6c5-9ed33116b34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0118, 0.0039, 0.0000, 0.0000, 0.0275,\n",
      "          0.0000, 0.1451, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0078, 0.0000,\n",
      "          0.1059, 0.3294, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.4667, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
      "          0.3451, 0.5608, 0.4314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863,\n",
      "          0.3647, 0.4157, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.2078,\n",
      "          0.5059, 0.4706, 0.5765, 0.6863, 0.6157, 0.6510, 0.5294, 0.6039,\n",
      "          0.6588, 0.5490, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0431, 0.5373,\n",
      "          0.5098, 0.5020, 0.6275, 0.6902, 0.6235, 0.6549, 0.6980, 0.5843,\n",
      "          0.5922, 0.5647, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
      "          0.0078, 0.0039, 0.0000, 0.0118, 0.0000, 0.0000, 0.4510, 0.4471,\n",
      "          0.4157, 0.5373, 0.6588, 0.6000, 0.6118, 0.6471, 0.6549, 0.5608,\n",
      "          0.6157, 0.6196, 0.0431, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0118, 0.0000, 0.0000, 0.3490, 0.5451, 0.3529,\n",
      "          0.3686, 0.6000, 0.5843, 0.5137, 0.5922, 0.6627, 0.6745, 0.5608,\n",
      "          0.6235, 0.6627, 0.1882, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0157,\n",
      "          0.0039, 0.0000, 0.0000, 0.0000, 0.3843, 0.5333, 0.4314, 0.4275,\n",
      "          0.4314, 0.6353, 0.5294, 0.5647, 0.5843, 0.6235, 0.6549, 0.5647,\n",
      "          0.6196, 0.6627, 0.4667, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0078, 0.0078, 0.0039, 0.0078, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1020, 0.4235, 0.4588, 0.3882, 0.4353, 0.4588,\n",
      "          0.5333, 0.6118, 0.5255, 0.6039, 0.6039, 0.6118, 0.6275, 0.5529,\n",
      "          0.5765, 0.6118, 0.6980, 0.0000],\n",
      "         [0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824,\n",
      "          0.2078, 0.3608, 0.4588, 0.4353, 0.4039, 0.4510, 0.5059, 0.5255,\n",
      "          0.5608, 0.6039, 0.6471, 0.6667, 0.6039, 0.5922, 0.6039, 0.5608,\n",
      "          0.5412, 0.5882, 0.6471, 0.1686],\n",
      "         [0.0000, 0.0000, 0.0902, 0.2118, 0.2549, 0.2980, 0.3333, 0.4627,\n",
      "          0.5020, 0.4824, 0.4353, 0.4431, 0.4627, 0.4980, 0.4902, 0.5451,\n",
      "          0.5216, 0.5333, 0.6275, 0.5490, 0.6078, 0.6314, 0.5647, 0.6078,\n",
      "          0.6745, 0.6314, 0.7412, 0.2431],\n",
      "         [0.0000, 0.2667, 0.3686, 0.3529, 0.4353, 0.4471, 0.4353, 0.4471,\n",
      "          0.4510, 0.4980, 0.5294, 0.5333, 0.5608, 0.4941, 0.4980, 0.5922,\n",
      "          0.6039, 0.5608, 0.5804, 0.4902, 0.6353, 0.6353, 0.5647, 0.5412,\n",
      "          0.6000, 0.6353, 0.7686, 0.2275],\n",
      "         [0.2745, 0.6627, 0.5059, 0.4078, 0.3843, 0.3922, 0.3686, 0.3804,\n",
      "          0.3843, 0.4000, 0.4235, 0.4157, 0.4667, 0.4706, 0.5059, 0.5843,\n",
      "          0.6118, 0.6549, 0.7451, 0.7451, 0.7686, 0.7765, 0.7765, 0.7333,\n",
      "          0.7725, 0.7412, 0.7216, 0.1412],\n",
      "         [0.0627, 0.4941, 0.6706, 0.7373, 0.7373, 0.7216, 0.6706, 0.6000,\n",
      "          0.5294, 0.4706, 0.4941, 0.4980, 0.5725, 0.7255, 0.7647, 0.8196,\n",
      "          0.8157, 1.0000, 0.8196, 0.6941, 0.9608, 0.9882, 0.9843, 0.9843,\n",
      "          0.9686, 0.8627, 0.8078, 0.1922],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0471, 0.2627, 0.4157, 0.6431, 0.7255,\n",
      "          0.7804, 0.8235, 0.8275, 0.8235, 0.8157, 0.7451, 0.5882, 0.3216,\n",
      "          0.0314, 0.0000, 0.0000, 0.0000, 0.6980, 0.8157, 0.7373, 0.6863,\n",
      "          0.6353, 0.6196, 0.5922, 0.0431],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]]), 9)\n"
     ]
    }
   ],
   "source": [
    "# 공개 데이터셋에서 학습 데이터를 내려받습니다.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# 공개 데이터셋에서 테스트 데이터를 내려받습니다.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "\n",
    "print(test_data[0]) # 이곳 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTcLqy5u8tZA"
   },
   "source": [
    "``Dataset`` 을 ``DataLoader`` 의 인자로 전달합니다. 이는 데이터셋을 순회 가능한 객체(iterable)로 감싸고, 자동화된 배치(batch), 샘플링(sampling),\n",
    "섞기(shuffle) 및 다중 프로세스로 데이터 불러오기(multiprocess data loading)를 지원합니다. 여기서는 배치 크기(batch size)를 64로 정의합니다.\n",
    "즉, 데이터로더(dataloader) 객체의 각 요소는 64개의 특징(feature)과 정답(label)을 묶음(batch)으로 반환합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsIQuJBk8tZA",
    "outputId": "74fb6683-f8bb-4479-9e4c-50b321f1449a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# 데이터로더를 생성합니다.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VPDAbMmz-nhm",
    "outputId": "9f1af31b-6b77-4471-b226-610b0a7fb4f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0118, 0.0039, 0.0000, 0.0000, 0.0275,\n",
       "          0.0000, 0.1451, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0078, 0.0000,\n",
       "          0.1059, 0.3294, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.4667, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "          0.3451, 0.5608, 0.4314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863,\n",
       "          0.3647, 0.4157, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.2078,\n",
       "          0.5059, 0.4706, 0.5765, 0.6863, 0.6157, 0.6510, 0.5294, 0.6039,\n",
       "          0.6588, 0.5490, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0431, 0.5373,\n",
       "          0.5098, 0.5020, 0.6275, 0.6902, 0.6235, 0.6549, 0.6980, 0.5843,\n",
       "          0.5922, 0.5647, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "          0.0078, 0.0039, 0.0000, 0.0118, 0.0000, 0.0000, 0.4510, 0.4471,\n",
       "          0.4157, 0.5373, 0.6588, 0.6000, 0.6118, 0.6471, 0.6549, 0.5608,\n",
       "          0.6157, 0.6196, 0.0431, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0118, 0.0000, 0.0000, 0.3490, 0.5451, 0.3529,\n",
       "          0.3686, 0.6000, 0.5843, 0.5137, 0.5922, 0.6627, 0.6745, 0.5608,\n",
       "          0.6235, 0.6627, 0.1882, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0157,\n",
       "          0.0039, 0.0000, 0.0000, 0.0000, 0.3843, 0.5333, 0.4314, 0.4275,\n",
       "          0.4314, 0.6353, 0.5294, 0.5647, 0.5843, 0.6235, 0.6549, 0.5647,\n",
       "          0.6196, 0.6627, 0.4667, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0078, 0.0078, 0.0039, 0.0078, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.1020, 0.4235, 0.4588, 0.3882, 0.4353, 0.4588,\n",
       "          0.5333, 0.6118, 0.5255, 0.6039, 0.6039, 0.6118, 0.6275, 0.5529,\n",
       "          0.5765, 0.6118, 0.6980, 0.0000],\n",
       "         [0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824,\n",
       "          0.2078, 0.3608, 0.4588, 0.4353, 0.4039, 0.4510, 0.5059, 0.5255,\n",
       "          0.5608, 0.6039, 0.6471, 0.6667, 0.6039, 0.5922, 0.6039, 0.5608,\n",
       "          0.5412, 0.5882, 0.6471, 0.1686],\n",
       "         [0.0000, 0.0000, 0.0902, 0.2118, 0.2549, 0.2980, 0.3333, 0.4627,\n",
       "          0.5020, 0.4824, 0.4353, 0.4431, 0.4627, 0.4980, 0.4902, 0.5451,\n",
       "          0.5216, 0.5333, 0.6275, 0.5490, 0.6078, 0.6314, 0.5647, 0.6078,\n",
       "          0.6745, 0.6314, 0.7412, 0.2431],\n",
       "         [0.0000, 0.2667, 0.3686, 0.3529, 0.4353, 0.4471, 0.4353, 0.4471,\n",
       "          0.4510, 0.4980, 0.5294, 0.5333, 0.5608, 0.4941, 0.4980, 0.5922,\n",
       "          0.6039, 0.5608, 0.5804, 0.4902, 0.6353, 0.6353, 0.5647, 0.5412,\n",
       "          0.6000, 0.6353, 0.7686, 0.2275],\n",
       "         [0.2745, 0.6627, 0.5059, 0.4078, 0.3843, 0.3922, 0.3686, 0.3804,\n",
       "          0.3843, 0.4000, 0.4235, 0.4157, 0.4667, 0.4706, 0.5059, 0.5843,\n",
       "          0.6118, 0.6549, 0.7451, 0.7451, 0.7686, 0.7765, 0.7765, 0.7333,\n",
       "          0.7725, 0.7412, 0.7216, 0.1412],\n",
       "         [0.0627, 0.4941, 0.6706, 0.7373, 0.7373, 0.7216, 0.6706, 0.6000,\n",
       "          0.5294, 0.4706, 0.4941, 0.4980, 0.5725, 0.7255, 0.7647, 0.8196,\n",
       "          0.8157, 1.0000, 0.8196, 0.6941, 0.9608, 0.9882, 0.9843, 0.9843,\n",
       "          0.9686, 0.8627, 0.8078, 0.1922],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0471, 0.2627, 0.4157, 0.6431, 0.7255,\n",
       "          0.7804, 0.8235, 0.8275, 0.8235, 0.8157, 0.7451, 0.5882, 0.3216,\n",
       "          0.0314, 0.0000, 0.0000, 0.0000, 0.6980, 0.8157, 0.7373, 0.6863,\n",
       "          0.6353, 0.6196, 0.5922, 0.0431],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0] # normalized 되어있는 FasionMNIST 데이터 # 이곳수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQurrLcz_R-_",
    "outputId": "29507e27-a9a0-48dc-f35f-e1536d5d36ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape# 이곳수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sznEBB_I_Y5R",
    "outputId": "322fe964-c3c0-487b-9801-50203c29fd30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "X_squeeze = X[0].squeeze() # 시각화 하기 편한형태로 변경 # 이곳 수정\n",
    "print(X_squeeze.shape) # 형태를 보여줌\n",
    "X_squeeze_numpy = X_squeeze.numpy() # tensor -> numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "10wX-_ns_y3W",
    "outputId": "5bb6f394-7f90-4d81-9937-7093685212c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'tensor(9)')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # 이곳 수정\n",
    "plt.imshow(X_squeeze_numpy)\n",
    "plt.title(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDJK-aLAAjpG",
    "outputId": "a100cdaf-607e-4e22-86af-7ded3c6edff1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g5lQCGL8tZA"
   },
   "source": [
    "[PyTorch에서 데이터를 불러오는 방법](data_tutorial.html) 을 자세히 알아보세요.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQ7z4lXt8tZB"
   },
   "source": [
    "------------------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pH1yX4c8tZB"
   },
   "source": [
    "## 모델 만들기\n",
    "PyTorch에서 신경망 모델은 [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) 을\n",
    "상속받는 클래스(class)를 생성하여 정의합니다. ``__init__`` 함수에서 신경망의 계층(layer)들을 정의하고 ``forward`` 함수에서\n",
    "신경망에 데이터를 어떻게 전달할지 지정합니다. 가능한 경우 GPU 또는 MPS로 신경망을 이동시켜 연산을 가속(accelerate)합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLotuxSV8tZB",
    "outputId": "532044bd-9d85-49a4-96b2-e428b0ddb709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 학습에 사용할 CPU나 GPU, MPS 장치를 얻습니다.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# 모델을 정의합니다.\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten() # image 를 fully connected layer에 넣기 위함\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(in_features = 28*28,out_features= 512),\n",
    "            nn.ReLU(), # 활성화 함수로 relu 사용\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10) # 출력값을 10개인 이유 : 10개 중 1개를 맞추는 분류모델 이므로.\n",
    "        )\n",
    "  # 신경망의 데이터를 어떻게 전달할지 정해줌\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WASvwte8tZB"
   },
   "source": [
    "[PyTorch에서 신경망을 정의하는 방법](buildmodel_tutorial.html) 을 자세히 알아보세요. -- 공식문서에서 확인해야할수도\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar-e-z6h8tZB"
   },
   "source": [
    "------------------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSPiWw4c8tZB"
   },
   "source": [
    "## 모델 매개변수 최적화하기\n",
    "모델을 학습하려면 [손실 함수(loss function)](https://pytorch.org/docs/stable/nn.html#loss-functions) 와\n",
    "[옵티마이저(optimizer)](https://pytorch.org/docs/stable/optim.html) 가 필요합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "hLlDknkc8tZB"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # SGD : Stochastic Gradient Descent # 주석 추가 # le-3 : 소수 셋째자리까지 확인."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjX15f9f8tZB"
   },
   "source": [
    "각 학습 단계(training loop)에서 모델은 (배치(batch)로 제공되는) 학습 데이터셋에 대한 예측을 수행하고,\n",
    "예측 오류를 역전파하여 모델의 매개변수를 조정합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "wnL-CFS88tZB"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 예측 오류 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y) # 손실값 계산 # 주석추가\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0: # 100번중에 한번만 확인 # 주석추가\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIZAQ45c8tZB"
   },
   "source": [
    "모델이 학습하고 있는지를 확인하기 위해 테스트 데이터셋으로 모델의 성능을 확인합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "LpcFAmGe8tZB"
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item() # 몇개 틀렸는지 맞았는지 확인할수 있다. # 주석추가\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLD-CRft8tZB"
   },
   "source": [
    "학습 단계는 여러번의 반복 단계 (*에폭(epochs)*) 를 거쳐서 수행됩니다. 각 에폭에서는 모델은 더 나은 예측을 하기 위해  매개변수를 학습합니다.\n",
    "각 에폭마다 모델의 정확도(accuracy)와 손실(loss)을 출력합니다; 에폭마다 정확도가 증가하고 손실이 감소하는 것을 보려고 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfzSXOR48tZB",
    "outputId": "49325c28-dfa4-4633-a4c6-8f850f4c447d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.162744  [   64/60000]\n",
      "loss: 1.171615  [ 6464/60000]\n",
      "loss: 0.986147  [12864/60000]\n",
      "loss: 1.127118  [19264/60000]\n",
      "loss: 0.999958  [25664/60000]\n",
      "loss: 1.029107  [32064/60000]\n",
      "loss: 1.054237  [38464/60000]\n",
      "loss: 0.996921  [44864/60000]\n",
      "loss: 1.038713  [51264/60000]\n",
      "loss: 0.977125  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.987355 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.042839  [   64/60000]\n",
      "loss: 1.071808  [ 6464/60000]\n",
      "loss: 0.872512  [12864/60000]\n",
      "loss: 1.032909  [19264/60000]\n",
      "loss: 0.910843  [25664/60000]\n",
      "loss: 0.935367  [32064/60000]\n",
      "loss: 0.974687  [38464/60000]\n",
      "loss: 0.922625  [44864/60000]\n",
      "loss: 0.959679  [51264/60000]\n",
      "loss: 0.908466  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.913838 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.954968  [   64/60000]\n",
      "loss: 1.002313  [ 6464/60000]\n",
      "loss: 0.790906  [12864/60000]\n",
      "loss: 0.965539  [19264/60000]\n",
      "loss: 0.850577  [25664/60000]\n",
      "loss: 0.866266  [32064/60000]\n",
      "loss: 0.918963  [38464/60000]\n",
      "loss: 0.872910  [44864/60000]\n",
      "loss: 0.902839  [51264/60000]\n",
      "loss: 0.858951  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.860808 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.887544  [   64/60000]\n",
      "loss: 0.950459  [ 6464/60000]\n",
      "loss: 0.730069  [12864/60000]\n",
      "loss: 0.915199  [19264/60000]\n",
      "loss: 0.807451  [25664/60000]\n",
      "loss: 0.813708  [32064/60000]\n",
      "loss: 0.876995  [38464/60000]\n",
      "loss: 0.838226  [44864/60000]\n",
      "loss: 0.860632  [51264/60000]\n",
      "loss: 0.821353  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.820667 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.834031  [   64/60000]\n",
      "loss: 0.909106  [ 6464/60000]\n",
      "loss: 0.682788  [12864/60000]\n",
      "loss: 0.876214  [19264/60000]\n",
      "loss: 0.774821  [25664/60000]\n",
      "loss: 0.772999  [32064/60000]\n",
      "loss: 0.843194  [38464/60000]\n",
      "loss: 0.812501  [44864/60000]\n",
      "loss: 0.828210  [51264/60000]\n",
      "loss: 0.791382  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.788893 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhKavYCZ8tZC"
   },
   "source": [
    "[모델을 학습하는 방법](optimization_tutorial.html) 을 자세히 알아보세요.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhcMYs3l8tZC"
   },
   "source": [
    "------------------------------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8i4lfvO8tZC"
   },
   "source": [
    "## 모델 저장하기\n",
    "모델을 저장하는 일반적인 방법은 (모델의 매개변수들을 포함하여) 내부 상태 사전(internal state dictionary)을\n",
    "직렬화(serialize)하는 것입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-jykBsL8tZC",
    "outputId": "ffe8e4b3-d24f-4d91-eed9-0ae0761ea372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aRHRrHQ8tZC"
   },
   "source": [
    "## 모델 불러오기\n",
    "\n",
    "모델을 불러오는 과정에는 모델 구조를 다시 만들고 상태 사전을 모델에 불러오는 과정이 포함됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "paSkr0rI8tZC",
    "outputId": "3b1791a5-629a-4ba9-e30c-a963f1c2f307"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCsWryYs8tZC"
   },
   "source": [
    "이제 이 모델을 사용해서 예측을 할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VJBUf4i8tZC",
    "outputId": "ba9df622-0f95-4892-d916-aacf33a2c6ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIWNK4hP8tZC"
   },
   "source": [
    "[모델을 저장하고 불러오는 방법](saveloadrun_tutorial.html) 을 자세히 알아보세요.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
